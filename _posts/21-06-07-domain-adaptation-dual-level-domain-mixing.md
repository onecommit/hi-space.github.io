---
title: Semi-supervised Domain Adaptation based on Dual-level Domain Mixing for Semantic Segmentation
category: AI
tags: ai paper ğŸ”¥
---

Multi teacher (Region-level teacherì™€ Sample-level teacher) ë¥¼ ì´ìš©í•´ student modelì—ê²Œ ê°ê¸° ë‹¤ë¥¸ ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë¥¼ í•™ìŠµì‹œì¼œì¤€ë‹¤. (Domain Mixing)

<!--more-->

# Paper

- **CVPR2021**
- [Paper](https://arxiv.org/pdf/2103.04705.pdf)
- [Related Post](https://hi-space.github.io/ai/2021/09/19/semi-supervised-domain-adaptation-dual-level-domain-mixing.html)

# Method

![](/assets/images/21-09-04-domain-adaptation-dual-level-domain-mixing-SSDA%20framework.png)

Dominì„ mixing í•œ multi teache ë¥¼ ì´ìš©í•´ student modelì—ê²Œ ê°ê¸° ë‹¤ë¥¸ ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë¥¼ í•™ìŠµì‹œì¼œì¤€ë‹¤.

- Region-level teacher
- Sample-level teacher

ë‘ê°œì˜ teacher modelì„ ensembleí•œ ëª¨ë¸ì´ domain-mixed teachers ì´ë‹¤.  
Domain gapì„ ì¤„ì´ê¸° ìœ„í•´ Region-level data mixing, sample-level data mixing ë‘ê°€ì§€ viewë¥¼ ì´ìš©í•œë‹¤.

### Region-level data mixing

Semantic segmentationì€ dense pixel-wise prediction taskë¡œ, ê° í”½ì…€ì˜ prediction ê°’ ì™¸ì— ì£¼ë³€ pixelì˜ regional í•œ prediction ê°’ë„ í•„ìš”í•˜ë‹¤. í•œ ì´ë¯¸ì§€ì— source, target ë„ë©”ì¸ ì´ë¯¸ì§€ê°€ í•¨ê»˜ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ëª¨ë¸ì€ domain-invariant representationì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤. ë‹¤ë¥¸ feature distributionì™€ ë‹¤ë¥¸ regionì„ ê°€ì§„ ê°’ì€ ë‘ê°€ì§€ë¥¼ ë™ì‹œì— ë°°ìš¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ ì•„ì´ë””ì–´ëŠ” CutMix ì—ì„œ ì˜ê°ì„ ë°›ì•˜ë‹¤. (ëª¨ë¸ì˜ generalization íŠ¹ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°ê¸° ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ë¶™ì—¬ì„œ augment í•¨) ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ëŠ” ë¹„ìŠ·í•œ í˜•íƒœë¡œ source domain ì´ë¯¸ì§€ì™€ target domain ì´ë¯¸ì§€ë¥¼ ì„ì–´ì„œ teacher modelì˜ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ domain gapì„ ì¤„ì¸ë‹¤. 

### Sample-level data mixing

Holistic viewì—ì„œ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ë°ì´í„°ë¥¼ ì„ëŠ”ë‹¤. Sourceì™€ target ë°ì´í„°ëŠ” í° distribution gapì´ ìˆì„ê±°ë‹¤. Source ë°ì´í„° ë§Œìœ¼ë¡œë§Œ í•™ìŠµì„ í•˜ë©´ overfitting ëª¨ë¸ì´ ë§Œë“¤ì–´ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— source, target ë°ì´í„°ë¥¼ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œë§í•´ì„œ teacher modelì˜ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤.

## Multi-teacher Knowledge Distillation

ì´ì œ pretrainëœ domain-mixed teacher ëª¨ë¸ì„ ë‘ê°œ ì–»ì—ˆë‹¤. ê·¸ ë‹¤ìŒì€ Knowledge Distillation(KD)ë¥¼ ì´ìš©í•´ ë‘ ëª¨ë¸ê°„ KL-divergenceë¥¼ ìµœì†Œí™” í•´ì•¼í•œë‹¤. 

ë‘ê°œì˜ teacher ëª¨ë¸ì´ ìˆê³  ë¹„ìŠ·í•œ í˜•íƒœì˜ student ëª¨ë¸ì´ í•˜ë‚˜ ìˆë‹¤. ë‘ê°œì˜ teacher modelì„ ì•™ìƒë¸”í•´ì„œ unlabeled dataì— labeling í•˜ê³  ê·¸ ë°ì´í„°ë¡œ student ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. ê·¸ë¦¬ê³  student modelì€ ì ì€ ì–‘ì˜ labeled dataë¡œ supervised learning  í•œë‹¤.

## Progressive Improving Scheme

ì¼ë°˜ì ìœ¼ë¡œ teacher modelì˜ ì„±ëŠ¥ì´ ë” ì¢‹ì€ë° distilling knowledgeë¥¼ ì´ìš©í•´ studnet modelë„ teacher modelì˜ ì„±ëŠ¥ìœ¼ë¡œ ëŒì–´ì˜¬ë ¤ë³´ì. 

Labeled source dataì™€ ì†ŒëŸ‰ì˜ labeled target dataë¥¼ í†µí•´ teacher modelì„ ì–»ì—ˆë‹¤. 

ì´ frameworkëŠ” iteratively í•™ìŠµì´ ì§„í–‰ë ê±°ê³  domain-mixed teacherì™€ studentëŠ” ëª¨ë‘ knowledge distillationì™€ self-training ê¸°ë²•ì„ í†µí•´ ëª¨ë‘ ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.